{"application":{"enable-perf-measurement":{"value":"1","Meaning":"Indicates whether the application performance measurement is enabled."},"perf-measurement-interval-sec":{"value":"10","Meaning":"The interval, in seconds, at which the performance metrics are sampled and printed."},"gie-kitti-output-dir":{"value":"\/home\/ubuntu\/kitti_data\/","Meaning":"Pathname of an existing directory where the application stores primary detector output in a modified KITTI metadata format."},"kitti-track-output-dir":{"value":"\/home\/ubuntu\/kitti_data_tracker\/","Meaning":"Pathname of an existing directory where the application stores tracker output in a modified KITTI metadata format."}},"tiled-display":{"enable":{"value":"1","Meaning":"Indicates whether tiled display is enabled. When user sets enable=2, first [sink] group with the key: link-to-demux=1 shall be linked to demuxer's src_[source_id] pad where source_id is the key set in the corresponding [sink] group."},"rows":{"value":"5","Meaning":"Number of rows in the tiled 2D array."},"columns":{"value":"6","Meaning":"Number of columns in the tiled 2D array."},"width":{"value":"1280","Meaning":"Width of the tiled 2D array, in pixels."},"height":{"value":"720","Meaning":"Height of the tiled 2D array, in pixels."},"gpu-id":{"value":"0","Meaning":"GPU to be used by the element in case of multiple GPUs."},"nvbuf-memory-type":{"value":"3","Meaning":"Type of memory the element is to allocate for output buffers.0 (nvbuf-mem-default): a platform-specific default type.1 (nvbuf-mem-cuda-pinned): pinned\/host CUDA memory.2 (nvbuf-mem-cuda-device): device CUDA memory.3 (nvbuf-mem-cuda-unified): unified CUDA memory.For dGPU: All values are valid.For Jetson: Only 0 (zero) is valid."}},"source":{"enable":{"value":"1","Meaning":"Enables or disables the source."},"type":{"value":"1","Meaning":"Type of source; other properties of the source depend on this type.1: Camera (V4L2).2: URI.3: MultiURI.4: RTSP.5: Camera (CSI) (Jetson only)."},"uri":{"value":"rtsp:\/\/127.0.0.1\/source1","Meaning":"URI to the encoded stream. The URI can be a file, an HTTP URI, or an RTSP live source. Valid when type=2 or 3. With MultiURI, the %d format specifier can also be used to specify multiple sources. The application iterates from 0 to num-sources 1 to generate the actual URIs."},"num-sources":{"value":"2","Meaning":"Number of sources. Valid only when type=3."},"intra-decode-enable":{"value":"1","Meaning":"Enables or disables intra-only decode."},"num-extra-surfaces":{"value":"5","Meaning":"Number of surfaces in addition to minimum decode surfaces given by the decoder. Can be used to manage the number of decoder output buffers in the pipeline."},"gpu-id":{"value":"1","Meaning":"GPU to be used by the element in case of multiple GPUs."},"camera-id":{"value":"2","Meaning":"Unique ID for the input source to be added to metadata. (Optional)"},"camera-width":{"value":"1920","Meaning":"GPU to be used by the element in case of multiple GPUs."},"camera-height":{"value":"1080","Meaning":"Height of frames to be requested from the camera, in pixels. Valid when type=1 or 5."},"camera-fps-n":{"value":"30","Meaning":"Numerator part of a fraction specifying the frame rate requested by the camera, in frames\/sec. Valid when the type=1 or 5."},"camera-fps-d":{"value":"1","Meaning":"Denominator part of a fraction specifying the frame rate requested from the camera, in frames\/sec. Valid when type = 1 or 5."},"camera-v4l2-dev-node":{"value":"1","Meaning":"Number of the V4L2 device node. For example, \/dev\/video<num> for the open source V4L2 camera capture path. Valid when the type setting (type of source) is 1."},"latency":{"value":"200","Meaning":"Jitterbuffer size in milliseconds; applicable only for RTSP streams."},"camera-csi-sensor-id":{"value":"1","Meaning":"Sensor ID of the camera module. Valid when the type (type of source) is 5."},"drop-frame-interval":{"value":"5","Meaning":"Interval to drop frames. For example, 5 means decoder outputs every fifth frame; 0 means no frames are dropped."},"nvbuf-memory-type":{"value":"1","Meaning":"Type of CUDA memory element is to allocate for output buffers.0 (cuda-pinned-mem): host\/pinned memory allocated with cudaMallocHost().1 (cuda-device-mem): Device memory allocated with cudaMalloc().2 (cuda-unified-mem): Unified memory allocated with cudaMallocManaged()."},"select-rtp-protocol":{"value":"4","Meaning":"Transport Protocol to use for RTP. Valid when type (type of source) is 4.0: UDP + UDP Multicast + TCP.4: TCP only."},"rtsp-reconnect-interval-sec":{"value":"60","Meaning":"Timeout in seconds to wait since last data was received from an RTSP source before forcing a reconnection. Setting it to 0 will disable the reconnection. Valid when type (type of source) is 4."},"smart-record":{"value":"1","Meaning":"Enable or disable the smart record."},"smart-rec-dir-path":{"value":"\/home\/nvidia\/","Meaning":"Path of directory to save the recorded file. By default, the current directory is used."},"smart-rec-file-prefix":{"value":"Cam1","Meaning":"Prefix of file name for recorded video. By default, Smart_Record is the prefix. For unique file names every source must be provided with a unique prefix."},"smart-rec-video-cache":{"value":"20","Meaning":"Size of video cache in seconds."},"smart-rec-container":{"value":"0","Meaning":"Container format of recorded video. MP4 and MKV containers are supported."},"smart-rec-start-time":{"value":"5","Meaning":"Number of seconds earlier from now to start the recording. E.g. if t0 is the current time and N is the start time in seconds that means recording will start from t0 \u2013 N. Obviously for it to work the video cache size must be greater than the N."},"smart-rec-default-duration":{"value":"20","Meaning":"In case a Stop event is not generated. This parameter will ensure the recording is stopped after a predefined default duration."},"smart-rec-duration":{"value":"15","Meaning":"Duration of recording in seconds."},"smart-rec-interval":{"value":"10","Meaning":"This is the time interval in seconds for SR start \/ stop events generation."}},"streammux":{"gpu-id":{"value":"1","Meaning":"GPU element is to use in case of multiple GPUs."},"live-source":{"value":"0","Meaning":"Informs the muxer that sources are live."},"batch-size":{"value":"4","Meaning":"Muxer batch size."},"batched-push-timeout":{"value":"40000","Meaning":"Timeout in microseconds after to push the batch after the first buffer is available, even if the complete batch is not formed."},"width":{"value":"1280","Meaning":"Muxer output width in pixels."},"height":{"value":"720","Meaning":"Muxer output height in pixels."},"enable-padding":{"value":"0","Meaning":"Indicates whether to maintain source aspect ratio when scaling by adding black bands."},"nvbuf-memory-type":{"value":"3","Meaning":"Type of CUDA memory the element is to allocate for output buffers.0 (nvbuf-mem-default, a platform-specific default1 (nvbuf-mem-cuda-pinned): pinned\/host CUDA memory.2 (nvbuf-mem-cuda-device): Device CUDA memory.3 (nvbuf-mem-cuda-unified): Unified CUDA memory.For dGPU: All values are valid.For Jetson: Only 0 (zero) is valid."},"attach-sys-ts-as-ntp":{"value":"0","Meaning":"For live sources, the muxed buffer shall have associated NvDsFrameMeta->ntp_timestamp set to system time or the server\u2019s NTP time when streaming RTSP. If set to 1, system timestamp will be attached as ntp timestamp.If set to 0, ntp timestamp from rtspsrc, if available, will be attached."},"config-file-path":{"value":"config_mux_source30.txt","Meaning":"This key is valid only for the new streammux. Please refer the plugin manual section \u201cNew Gst-nvstreammux\u201d for more information. Absolute or relative (to DS config-file location) path of mux configuration file."}},"primary-gie":{"enable":{"value":"1","Meaning":"Indicates whether the primary GIE must be enabled."},"gie-unique-id":{"value":"2","Meaning":"Unique component ID to be assigned to the nvinfer instance. Used to identify metadata generated by the instance."},"gpu-id":{"value":"1","Meaning":"GPU to be used by the element in case of multiple GPUs."},"nvbuf-memory-type":{"value":"3","Meaning":"Type of CUDA memory element is to allocate for output buffers.0 (nvbuf-mem-default): a platform-specific default1 (nvbuf-mem-cuda-pinned): pinned\/host CUDA memory2 (nvbuf-mem-cuda-device): Device CUDA memory3 (nvbuf-mem-cuda-unified): Unified CUDA memoryFor dGPU: All values are valid.For Jetson: Only 0 (zero) is valid."},"config-file":{"value":"\/home\/ubuntu\/config_infer_resnet.txt","Meaning":"Pathname of a configuration file which specifies properties for the Gst-nvinfer plugin. It may contain any of the properties described in this table except config-file itself. Properties must be defined in a group named [property].For more details about parameters see \u201cGst-nvinfer File Configuration Specifications\u201d in the DeepStream 4.0 Plugin Manual."},"batch-size":{"value":"2","Meaning":"The number of frames(P.GIE)\/objects(S.GIE) to be inferred together in a batch."},"interval":{"value":"2","Meaning":"Number of consecutive batches to skip for inference."},"bbox-border-color":{"value":"1;0;0;1","Meaning":"The color of the borders for the objects of a specific class ID, specified in RGBA format. The key must be of format bbox-border-color<class-id>. This property can be identified multiple times for multiple class IDs. If this property is not identified for the class ID, the borders are not drawn for objects of that class-id."}},"secondary-gie":{"enable":{"value":"1","Meaning":"Indicates whether the primary GIE must be enabled."},"gie-unique-id":{"value":"2","Meaning":"Unique component ID to be assigned to the nvinfer instance. Used to identify metadata generated by the instance."},"gpu-id":{"value":"1","Meaning":"GPU to be used by the element in case of multiple GPUs."},"config-file":{"value":"\/home\/ubuntu\/config_infer_resnet.txt","Meaning":"Pathname of a configuration file which specifies properties for the Gst-nvinfer plugin. It may contain any of the properties described in this table except config-file itself. Properties must be defined in a group named [property].For more details about parameters see \u201cGst-nvinfer File Configuration Specifications\u201d in the DeepStream 4.0 Plugin Manual."},"batch-size":{"value":"2","Meaning":"The number of frames(P.GIE)\/objects(S.GIE) to be inferred together in a batch."},"operate-on-gie-id":{"value":"1","Meaning":"A unique ID of the GIE, on whose metadata (NvDsFrameMeta) this GIE is to operate."},"operate-on-class-ids":{"value":"1;2","Meaning":"Class IDs of the parent GIE on which this GIE must operate. The parent GIE is specified using operate-on-gie-id."}},"tracker":{"enable":{"value":"1","Meaning":"Enables or disables the tracker."},"tracker-width":{"value":"960","Meaning":"Frame width at which the tracker will operate, in pixels."},"tracker-height":{"value":"540","Meaning":"Frame height at which the tracker will operate, in pixels."},"gpu-id":{"value":"1","Meaning":"GPU to be used by the element in case of multiple GPUs."},"ll-config-file":{"value":"iou_config.txt","Meaning":"Pathname for the low-level tracker configuration file."},"ll-lib-file":{"value":"\/usr\/local\/deepstream\/libnvds_mot_iou.so","Meaning":"Pathname for the low-level tracker implementation library."},"enable-batch-process":{"value":"1","Meaning":"Enables batch processing across multiple streams."},"enable-past-frame":{"value":"1","Meaning":"Enables reporting past-frame data"}},"message-converter":{"enable":{"value":"1","Meaning":"Enables or disables the message converter."},"msg-conv-config":{"value":"dstest5_msgconv_sample_config.txt","Meaning":"Pathname of the configuration file for the Gst-nvmsgconv element."},"msg-conv-payload-type":{"value":"0","Meaning":"Type of payload.0, PAYLOAD_DEEPSTREAM: Deepstream schema payload.1, PAYLOAD_DEEPSTREAM_MINIMAL: Deepstream schema payload minimal.256, PAYLOAD_RESERVED: Reserved type.257, PAYLOAD_CUSTOM: Custom schema payload."},"msg-conv-msg2p-lib":{"value":"\/opt\/nvidia\/deepstream\/deepstream-4.0\/lib\/libnvds_msgconv.so","Meaning":"Absolute pathname of an optional custom payload generation library. This library implements the API defined by sources\/libs\/nvmsgconv\/nvmsgconv.h. Applicable only when msg-conv-payload-type=257, PAYLOAD_CUSTOM."},"msg-conv-comp-id":{"value":"1","Meaning":"comp-id Gst property of the gst-nvmsgconv element. This is the Id of the component that attaches the NvDsEventMsgMeta which must be processed by gst-nvmsgconv element."}},"message-consumer":{"enable":{"value":"1","Meaning":"Enables or disables the message consumer."},"proto-lib":{"value":"\/opt\/nvidia\/deepstream\/deepstream-4.0\/lib\/libnvds_kafka_proto.so","Meaning":"Path to the library having protocol adapter implementation."},"conn-str":{"value":"0","Meaning":"foo.bar.com;80"},"config-file":{"value":"..\/cfg_kafka.txt","Meaning":"Path to the file having additional configurations for protocol adapter."},"subscribe-topic-list":{"value":"toipc1;topic2;topic3","Meaning":"List of topics to subscribe."}},"osd":{"enable":{"value":"1","Meaning":"Enables or disables the On-Screen Display (OSD)."},"gpu-id":{"value":"1","Meaning":" GPU to be used by the element in case of multiple GPUs."},"border-width":{"value":"10","Meaning":"Border width of the bounding boxes drawn for objects, in pixels."},"border-color":{"value":"0;0;0.7;1","Meaning":"Border color of the bounding boxes drawn for objects."},"text-size":{"value":"16","Meaning":"Size of the text that describes the objects, in points."},"text-color":{"value":"0;0;0.7;1","Meaning":"The color of the text that describes the objects, in RGBA format."},"text-bg-color":{"value":"0;0;0;0.5","Meaning":"The background color of the text that describes the objects, in RGBA format."},"clock-text-size":{"value":"16","Meaning":"The size of the clock time text, in points."},"clock-x-offset":{"value":"100","Meaning":"The horizontal offset of the clock time text, in pixels."},"clock-y-offset":{"value":"100","Meaning":"The vertical offset of the clock time text, in pixels."},"font":{"value":"Purisa","Meaning":"Name of the font for text that describes the objects. Enter the shell command fc-list to display the names of available fonts."},"show-clock":{"value":"0","Meaning":"Enables or disables overlay of the clock time on the frame."},"clock-color":{"value":"1;0;0;1","Meaning":"Color of the clock time text, in RGBA format."},"nvbuf-memory-type":{"value":"3","Meaning":"Type of CUDA memory the element is to allocate for output buffers.0 (nvbuf-mem-default): a platform-specific default1 (nvbuf-mem-cuda-pinned): pinned\/host CUDA memory2 (nvbuf-mem-cuda-device): Device CUDA memory3 (nvbuf-mem-cuda-unified): Unified CUDA memoryFor dGPU: All values are valid.For Jetson: Only 0 (zero) is valid."},"process-mode":{"value":"1","Meaning":"NvOSD processing mode.0: CPU.1: GPU (dGPU only).2: Hardware (Jetson only)."}},"sink":{"enable":{"value":"","Meaning":"Enables or disables the sink."},"type":{"value":"","Meaning":"Type of sink, to use..1: Fakesink.2: EGL based windowed sink (nveglglessink).3: Encode + File Save (encoder + muxer + filesink).4: Encode + RTSP streaming.5: Overlay (Jetson only).6: Message converter + Message broker."},"sync":{"value":"","Meaning":"Indicates how fast the stream is to be rendered..0: As fast as possible.1: Synchronously."},"qos":{"value":"","Meaning":"ndicates whether the sink is to generate Quality-of-Service events, which can lead to the pipeline dropping frames when pipeline FPS cannot keep up with the stream frame rate."},"source-id":{"value":"","Meaning":"The ID of the source whose buffers this sink must use. The source ID is contained in the source group name. For example, for group [source1] source-id=1."},"gpu-id":{"value":"","Meaning":"GPU to be used by the element in case of multiple GPUs."},"container":{"value":"","Meaning":"Container to use for the file save. Only valid for type=3.1: MP4.2: MKV."},"codec":{"value":"","Meaning":"The encoder to be used to save the file..1: H.264 (hardware).2: H.265 (hardware)."},"bitrate":{"value":"","Meaning":"Bitrate to use for encoding, in bits per second. Valid for type=3 and 4."},"iframeinterval":{"value":"","Meaning":"Encoding intra-frame occurrence frequency."},"output-file":{"value":"","Meaning":"Pathname of the output encoded file. Only valid for type=3."},"nvbuf-memory-type":{"value":"","Meaning":"Type of CUDA memory the plugin is to allocate for output buffers..0 (nvbuf-mem-default): a platform-specific default.1 (nvbuf-mem-cuda-pinned): pinned\/host CUDA memory.2 (nvbuf-mem-cuda-device): Device CUDA memory.3 (nvbuf-mem-cuda-unified): Unified CUDA memory.For dGPU: All values are valid.For Jetson: Only 0 (zero) Is valid."},"rtsp-port":{"value":"","Meaning":"Port for the RTSP streaming server; a valid unused port number. Valid for type=4."},"udp-port":{"value":"","Meaning":"Port used internally by the streaming implementation - a valid unused port number. Valid for type=4."},"overlay-id":{"value":"","Meaning":"Index of the overlay to use for HEAD 0. Valid for overlay sinks (type=5)."},"width":{"value":"","Meaning":"Width of the renderer in pixels."},"height":{"value":"","Meaning":"Height of the renderer in pixels."},"offset-x":{"value":"","Meaning":"Horizontal offset of the renderer window, in pixels."},"offset-y":{"value":"","Meaning":"Vertical offset of the renderer window, in pixels."},"display-id":{"value":"","Meaning":"ID of the display HEAD. Valid for overlay sinks (type=5)."},"msg-conv-config":{"value":"","Meaning":"Pathname of the configuration file for the Gst-nvmsgconv element (type=6)."},"msg-broker-proto-lib":{"value":"","Meaning":"Path to the protocol adapter implementation used Gst-nvmsgbroker (type=6)."},"msg-broker-conn-str":{"value":"","Meaning":"Connection string of the backend server (type=6)."},"topic":{"value":"","Meaning":"Name of the message topic (type=6)."},"msg-conv-payload-type":{"value":"","Meaning":"Type of payload.0, PAYLOAD_DEEPSTREAM: DeepStream schema payload.1, PAYLOAD_DEEPSTREAM_MINIMAL: DeepStream schema payload minimal.256, PAYLOAD_RESERVED: Reserved type.257, PAYLOAD_CUSTOM: Custom schema payload (type=6)."},"msg-broker-config":{"value":"","Meaning":"Pathname of an optional configuration file for the Gst-nvmsgbroker element (type=6)."},"msg-conv-msg2p-lib":{"value":"","Meaning":"Absolute pathname of an optional custom payload generation library. This library implements the API defined by sources\/libs\/nvmsgconv\/nvmsgconv.h.Applicable only when msg-conv-payload-type=257, PAYLOAD_CUSTOM."},"msg-conv-comp-id":{"value":"","Meaning":"comp-id Gst property of the nvmsgconv element; ID (gie-unique-id) of the primary\/secondary-gie component from which metadata is to be processed."},"msg-broker-comp-id":{"value":"","Meaning":"comp-id Gst property of the nvmsgbroker element; ID (gie-unique-id) of the primary\/secondary gie component from which metadata is to be processed."},"disable-msgconv":{"value":"","Meaning":"Only add a message broker component instead of a message converter + message broker.(type=6)"},"enc-type":{"value":"","Meaning":"Engine to use for encoder.0: NVENC hardware engine.1: CPU software encoder"},"profile (HW)":{"value":"","Meaning":"Encoder profile for the codec.V4L2 H264 encoder(HW):.0: Baseline.2: Main.4: High.V4L2 H265 encoder(HW):0: Main.1: Main10"},"udp-buffer-size":{"value":"","Meaning":"UDP kernel buffer size (in bytes) for internal RTSP output pipeline."},"link-to-demux":{"value":"","Meaning":"A boolean which enables or disables streaming a particular \u201csource-id\u201d alone to this sink. Please check the tiled-display group enable key for more information."}},"tests":{"file-loop":{"value":"1","Meaning":"Indicates whether input files should be looped infinitely."}}}